@InProceedings{barral2020,
  title = 	 {Non-Invasive Classification of Alzheimer’s Disease Using Eye Tracking and Language},
  author =       {Barral, Oswald and Jang, Hyeju and Newton-Mason, Sally and Shajan, Sheetal and Soroski, Thomas and Carenini, Giuseppe and Conati, Cristina and Field, Thalia},
  booktitle = 	 {Proceedings of the 5th Machine Learning for Healthcare Conference},
%  pages = 	 {813--841},
  year = 	 {2020},
%  editor = 	 {Doshi-Velez, Finale and Fackler, Jim and Jung, Ken and Kale, David and Ranganath, Rajesh and Wallace, Byron and Wiens, Jenna},
%  volume = 	 {126},
%  series = 	 {Proceedings of Machine Learning Research},
%  month = 	 {07--08 Aug},
  publisher =    {PMLR},
%  pdf = 	 {http://proceedings.mlr.press/v126/barral20a/barral20a.pdf},
%  url = 	 {https://proceedings.mlr.press/v126/barral20a.html},
%  abstract = 	 {Alzheimer’s disease (AD) is an insidious progressive neurodegenerative disease resulting in impaired cognition, dementia, and eventual death. At the earliest stages of the disease, decline in multiple cognitive domains including speech and eye movements occurs, and worsens with disease progression. Therefore, investigating speech and eye movements is promising as a non-invasive method for early classification of AD. While related work has investigated AD classification using speech collected during spontaneous speech tasks, no prior research has studied the utility of eye movements and their combination with speech for this classification task. In this paper, we present classification experiments with speech and eye movement data collected from 68 memory clinic patients (with a diagnosis of AD, mixed dementia, mild cognitive impairment, or subjective memory complaints) and 73 healthy volunteers completing the Cookie Theft picture description task. We show that eye tracking data is predictive of AD in a patient versus control classification task (AUC = .73). Furthermore, we show that using eye tracking data for this predictive task is complementary to using speech alone, as combining both modalities yields to the best classification performance (AUC=.80). Our results suggest that eye tracking is a useful modality for classification of AD, most promising when considered as an additional noninvasive modality to speech-based classification.}
}

@article{oyster1999,
  title={The human eye},
  author={Oyster, Clyde W},
  journal={Sunderland, MA: Sinauer},
  year={1999}
}

@article{colin1986,
  author = {Ware, Colin and Mikaelian, Harutune H.},
  title = {An Evaluation of an Eye Tracker as a Device for Computer Input2},
  year = {1986},
%  issue_date = {May 1987},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
%  volume = {17},
%  number = {SI},
%  issn = {0736-6906},
%  url = {https://doi.org/10.1145/30851.275627},
%  doi = {10.1145/30851.275627},
%  abstract = {Since humans direct their visual attention by means of eye movements, a device which monitors eye movements should be a natural “pick” device for selecting objects visually present on a monitor. The results from an experimental investigation of an eye tracker as a computer input device are presented. Three different methods were used to select the object looked at; these were a button press, prolonged fixation or “dwell” and an on screen select button. The results show that an eye tracker can be used as a fast selection device providing that the target size is not too small. If the targets are small speed declines and errors increase rapidly.}, journal = {SIGCHI Bull.},
%  month = may,
%  pages = {183–188},
%  numpages = {6},
%  keywords = {eye movements, input devices}
}

@INPROCEEDINGS{corno2002,  
  author={Corno, F. and Farinetti, L. and Signorile, I.},
  booktitle={Proceedings. IEEE International Conference on Multimedia and Expo},
  title={A cost-effective solution for eye-gaze assistive technology},
  year={2002},
%  volume={2},
%  pages={433-436 vol.2},
%  doi={10.1109/ICME.2002.1035632}
}

@article{barry1994,
  author = {Barry, Philip and Dockery, John and Littman, David and Barry, Melanie},
  title = "{Intelligent Assistive Technologies}",
  journal = {Presence: Teleoperators and Virtual Environments},
%    volume = {3},
%    number = {3},
%    pages = {208-215},
  year = {1994},
%    month = {08},
%    abstract = "{Intelligent assistive technology (IAT) refers to the integration of existing assistive technology with artificial intelligence (AI) techniques and advanced environment interfaces. AI can be used to integrate a great deal of sensor information, to amplify primary intent as well as to conduct background tasks. Through the application of AI we believe that we can level the playing field for persons with disabilities and maximize existing and future capabilities of assistive devices. By beginning a dialogue now between the developers of AI and assistive technology, IAT can become a reality.}",
%    doi = {10.1162/pres.1994.3.3.208},
%    url = {https://doi.org/10.1162/pres.1994.3.3.208},
%    eprint = {https://direct.mit.edu/pvar/article-pdf/3/3/208/1622718/pres.1994.3.3.208.pdf},
}

@inproceedings{smith2006,
  author = {Smith, J. David and Graham, T. C. Nicholas},
  title = {Use of Eye Movements for Video Game Control},
  year = {2006},
%  isbn = {1595933808},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
%  url = {https://doi.org/10.1145/1178823.1178847},
%  doi = {10.1145/1178823.1178847},
%  abstract = {We present a study that explores the use of a commercially available eye tracker as a control device for video games. We examine its use across multiple gaming genres and present games that utilize the eye tracker in a variety of ways. First, we describe a first-person shooter that uses the eyes to control orientation. Second, we study the use of eye movements for more natural interaction with characters in a role playing game. And lastly, we examine the use of eye tracking as a means to control a modified version of the classic action/arcade game Missile Command. Our results indicate that the use of an eye tracker can increase the immersion of a video game and can significantly alter the gameplay experience.},
%  booktitle = {Proceedings of the 2006 ACM SIGCHI International Conference on Advances in Computer Entertainment Technology},
%  pages = {20–es},
%  keywords = {eye tracking, video games},
  location = {Hollywood, California, USA},
%  series = {ACE '06}
}

@inproceedings{leyba2004,
  title={Eye Tracking as an Aiming Device in a Computer Game},
  author={J. D. Leyba and Jimi Malcolm},
  year={2004}
}

@misc{tobii2017,
  title = {Eye Tracking in Gaming, How Does it Work?},
%  howpublished = {\url{https://help.tobii.com/hc/en-us/articles/115003295025-Eye-tracking-in-gaming-how-does-it-work-}},
  year = {2017},
  author = {Tobii},
  note = {Accessed: 2021-10-17}
}

@article{antunes2018,
  title={A study on the use of eye tracking to adapt gameplay and procedural content generation in first-person shooter games},
  author={Jo{\~a}o Antunes and Pedro F. Santana},
  journal={ArXiv},
  year={2018},
%  volume={abs/1801.01565}
}

@article{mangeloja2019,
  author = {Mangeloja, Esa},
  title = {Economics of Esports},
  year = {2019},
  publisher = {Electronic Journal of Business Ethics and Organization Studies.},
%  journal = {T. Takala, T. Auvinen, M. Vesa, J. Tienari, P. Sajasalo, S. Heikkinen, J. Helms Mills, & M. Kallinen-Kuisma (Eds.), Electronic Journal of Business Ethics and Organization Studies. Vol. 24, No. 2. Special issue: Implications of Digitalization on Organizations and Leadership : Esports, Gamification and Beyond},
%  url = {http://ejbo.jyu.fi/pdf/ejbo_vol24_no2_pages_34-42.pdf}
}

@report{newzoo2021,
  author = {Newzoo},
  year = {2021},
  title = {Free 2018 Global Esports Market Report},
%  address = {Amsterdam: Newzoo}
}

@article{zemblys2018,
  author = {Zemblys, Raimondas and Niehorster, Diederick C. and Komogortsev, Oleg and Holmqvist, Kenneth},
  title = {Using machine learning to detect events in eye-tracking data},
  year = {2018},
%  issue_date = {Feb 2018},
%  volume = {50},
%  issn = {1554-3528},
%  url = {https://doi.org/10.3758/s13428-017-0860-3},
%  doi = {10.3758/s13428-017-0860-3},
%  abstract = {Event detection is a challenging stage in eye movement data analysis. A major drawback of current event detection methods is that parameters have to be adjusted based on eye movement data quality. Here we show that a fully automated classification of raw gaze samples as belonging to fixations, saccades, or other oculomotor events can be achieved using a machine-learning approach. Any already manually or algorithmically detected events can be used to train a classifier to produce similar classification of other data without the need for a user to set parameters. In this study, we explore the application of random forest machine-learning technique for the detection of fixations, saccades, and post-saccadic oscillations (PSOs). In an effort to show practical utility of the proposed method to the applications that employ eye movement classification algorithms, we provide an example where the method is employed in an eye movement-driven biometric application. We conclude that machine-learning techniques lead to superior detection compared to current state-of-the-art event detection algorithms and can reach the performance of manual coding.},
%  journal = {Behavior Research Methods},
%  month = feb,
%  pages = {160–181},
%  numpages = {21},
}

@book{Holmqvist2017,
author = {Holmqvist, Kenneth and Andersson, Richard},
year = {2017},
month = {11},
pages = {},
title = {Eye-tracking: A comprehensive guide to methods, paradigms and measures},
%isbn = {ISBN-13: 978-1979484893}
}

@Inbook{vanGog2013,
  author="Gog, Tamara van
  and Jarodzka, Halszka",
  editor="Azevedo, Roger
  and Aleven, Vincent",
  title="Eye Tracking as a Tool to Study and Enhance Cognitive and Metacognitive Processes in Computer-Based Learning Environments",
  bookTitle="International Handbook of Metacognition and Learning Technologies",
  year="2013",
  publisher="Springer New York",
  address="New York, NY",
  pages="143--156",
  abstract="This chapter discusses the use of eye tracking to assess cognitive and metacognitive processes and cognitive load in computer-based learning environments. Benefits of eye tracking for studying such processes are discussed (e.g., the very detailed information it provides on where a participant was looking, in what order, and for how long), but also limitations (e.g., that detailed information does not tell one which processes exactly are occurring; this has to be inferred by the researcher). In addition, this chapter provides examples of how eye tracking can be used to improve the design of instruction in computer-based learning environments, both indirectly and directly. For example, an indirect way would be to use the information on experts' or successful performers' viewing patterns to adapt instructions prior to a task (e.g., emphasizing what should be attended to later on) or to adapt the format of the task (e.g., cueing attention). A more direct way would be to display experts' or successful performers' eye movements overlaid onto the instructional materials. In the discussion, the opportunities provided by eye tracking, but also the technical challenges it poses are addressed.",
  %isbn="978-1-4419-5546-3",
  %doi="10.1007/978-1-4419-5546-3_10",
  %url="https://doi.org/10.1007/978-1-4419-5546-3_10"
}

@article{kahneman1966,
  title={Pupil Diameter and Load on Memory},
  author={Daniel Kahneman and Jackson Beatty},
  journal={Science},
  year={1966},
  volume={154},
  pages={1583 - 1585}
}

@article{may1990,
  title = {Eye movement indices of mental workload},
  journal = {Acta Psychologica},
  volume = {75},
  number = {1},
  pages = {75-89},
  year = {1990},
  %issn = {0001-6918},
  %doi = {https://doi.org/10.1016/0001-6918(90)90067-P},
  %url = {https://www.sciencedirect.com/science/article/pii/000169189090067P},
  author = {James G. May and Robert S. Kennedy and Mary C. Williams and William P. Dunlap and Julie R. Brannan},
  abstract = {Four investigations were carried out to assess the feasibility of using eye movement measures as indices of mental workload. In the first experiment, saccadic extent was measured during free viewing while subjects performed low, moderate and high complexity, auditory tone counting as the workload tasks. The range of saccadis extent decreased significantly as tone counting complexity (workload) was increased. In the second experiment the range of spontaneous saccades was measured under three levels of counting complexity with a visual task that did not require fixation or tracking. The results indicated that the extent of saccadic eye movements was significantly restricted as counting complexity increased. In the third experiment, the effects of practice were examined and decreased saccadic range under high tone counting complexity was observed even when significant increases in performance occured with practice. Finally, in experiment 4, the first experiment was repeated with additional optokinetic stimulation and the saccadic range was again observed to decrease with tone counting complexity. The results indicated that the extent of spontaneous and elicited eye movements was significantly restricted as counting complexity increased. We conclude that this measure may provide a valuable index of mental workload.}
}

@article{beatty1982,
  title={Task-evoked pupillary responses, processing load, and the structure of processing resources.},
  author={Jackson Beatty},
  journal={Psychological bulletin},
  year={1982},
  volume={91 2},
  pages={
          276-92
        }
}

@article{barbato1995,
  title={Effects of sleep deprivation on spontaneous eye blink rate and alpha EEG power},
  author={Giuseppe Barbato and Gianluca Ficca and Michele Beatrice and Margherita Casiello and Giovanni Muscettola and Franco Rinaldi},
  journal={Biological Psychiatry},
  year={1995},
  volume={38},
  pages={340-341}
}

@article{chen2014,
  author = {Chen, Siyuan and Epps, Julien},
  year = {2014},
  month = {04},
  pages = {},
  title = {Using Task-Induced Pupil Diameter and Blink Rate to Infer Cognitive Load},
  volume = {29},
  journal = {Human-Computer Interaction},
  %doi = {10.1080/07370024.2014.892428}
}

@article{seeber2013,
  author = {Seeber, Kilian},
  year = {2013},
  month = {03},
  pages = {},
  title = {Cognitive load in simultaneous interpreting: Measures and methods},
  volume = {25},
  journal = {Target},
  %doi = {10.1075/target.25.1.03see}
}

@inbook{klatzky2012,
  author = {Klatzky, Roberta and Giudice, Nicholas},
  year = {2012},
  month = {01},
  pages = {162-191},
  title = {Sensory substitution of vision: Importance of perceptual and cognitive processing},
  journal = {Assistive Technology for Blindness and Low Vision}
}

@article{eckstein2017,
  title = {Beyond eye gaze: What else can eyetracking reveal about cognition and cognitive development?},
  journal = {Developmental Cognitive Neuroscience},
  volume = {25},
  pages = {69-91},
  year = {2017},
  note = {Sensitive periods across development},
  %issn = {1878-9293},
  %doi = {https://doi.org/10.1016/j.dcn.2016.11.001},
  %url = {https://www.sciencedirect.com/science/article/pii/S1878929316300846},
  author = {Maria K. Eckstein and Belén Guerra-Carrillo and Alison T. {Miller Singley} and Silvia A. Bunge},
  keywords = {Eyetracking, Saccades, Pupillometry, Pupil dilation, Blink rate, Children},
  %abstract = {This review provides an introduction to two eyetracking measures that can be used to study cognitive development and plasticity: pupil dilation and spontaneous blink rate. We begin by outlining the rich history of gaze analysis, which can reveal the current focus of attention as well as cognitive strategies. We then turn to the two lesser-utilized ocular measures. Pupil dilation is modulated by the brain’s locus coeruleus-norepinephrine system, which controls physiological arousal and attention, and has been used as a measure of subjective task difficulty, mental effort, and neural gain. Spontaneous eyeblink rate correlates with levels of dopamine in the central nervous system, and can reveal processes underlying learning and goal-directed behavior. Taken together, gaze, pupil dilation, and blink rate are three non-invasive and complementary measures of cognition with high temporal resolution and well-understood neural foundations. Here we review the neural foundations of pupil dilation and blink rate, provide examples of their usage, describe analytic methods and methodological considerations, and discuss their potential for research on learning, cognitive development, and plasticity.}
}

@article{ballard1992,
 %ISSN = {09628436},
 %URL = {http://www.jstor.org/stable/57065},
 abstract = {The small angle subtended by the human fovea places a premium on the ability to quickly and accurately direct the gaze to targets of interest. Thus the resultant saccadic eye fixations are a very instructive behaviour, revealing much about the underlying cognitive mechanisms that guide them. Of particular interest are the eye fixations used in hand-eye coordination. Such coordination has been extensively studied for single movements from a source location to a target location. In contrast, we have studied multiple fixations where the sources and targets are a function of a task and chosen dynamically by the subject according to task requirements. The task chosen is a copying task: subjects must copy a figure made up of contiguous coloured blocks as fast as possible. The main observation is that although eye fixations are used for the terminal phase of hand movements, they are used for other tasks before and after that phase. The analysis of the spatial and temporal details of these fixations suggests that the underlying decision process that moves the eyes leaves key decisions until just before they are required.},
 author = {Dana H. Ballard and Mary M. Hayhoe and Feng Li and Steven D. Whitehead and J. P. Frisby and J. G. Taylor and R. B. Fisher},
 journal = {Philosophical Transactions: Biological Sciences},
 number = {1281},
 pages = {331--339},
 publisher = {The Royal Society},
 title = {Hand-Eye Coordination during Sequential Tasks [and Discussion]},
 volume = {337},
 year = {1992}
}

@article{land1999,
  author = {Land, M. and Mennie, Neil and Rusted, Jennifer},
  year = {1999},
  month = {02},
  pages = {1311-28},
  title = {The Roles of Vision and Eye Movements in the Control of Activities of Daily Living},
  volume = {28},
  journal = {Perception},
  %doi = {10.1068/p2935}
}

@inbook{knight2014,
  author = {Knight, Bruce and Horsley, Mike and Eliot, Matt},
  year = {2014},
  month = {12},
  pages = {281-285},
  title = {Eye Tracking and the Learning System: An Overview},
  %isbn = {978-3-319-02867-5},
  %doi = {10.1007/978-3-319-02868-2_22}
}

@article{vangog2009,
  title = {Attention guidance during example study via the model's eye movements},
  journal = {Computers in Human Behavior},
  volume = {25},
  number = {3},
  pages = {785-791},
  year = {2009},
  note = {Including the Special Issue: Enabling elderly users to create and share self authored multimedia content},
  %issn = {0747-5632},
  %doi = {https://doi.org/10.1016/j.chb.2009.02.007},
  %url = {https://www.sciencedirect.com/science/article/pii/S0747563209000338},
  author = {Gog, Tamara van and Halszka Jarodzka and Katharina Scheiter and Peter Gerjets and Fred Paas},
  keywords = {Example-based learning, Eye tracking, Cognitive load, Attention},
  abstract = {Research has shown that guiding students' attention guides their thought, and that attention can be communicated via eye movements. Therefore, this study investigates whether such a procedure can further enhance the effectiveness of examples in which a solution procedure is demonstrated to students by a (expert) model. Students’ attention was guided by showing them not only the model’s problem-solving actions on the computer screen, but also the model’s eye movements while doing so. Interestingly, results show that combined with a verbal description of the thought process, this form of attention guidance had detrimental effects on learning. Consequences for further research on attention guidance and instructional design are discussed.}
}

@article{rayner2008,
  author = {Castelhano, Monica and Rayner, Keith},
  year = {2008},
  month = {01},
  pages = {},
  title = {Eye movements during reading, visual search, and scene perception: An overview}
}

@article{rayner1998,
  title={Eye movements in reading and information processing: 20 years of research.},
  author={Keith Rayner},
  journal={Psychological bulletin},
  year={1998},
  volume={124 3},
  pages={
          372-422
        }
}

@article {hartridge1948,
	author = {Hartridge, H. and Thomson, L. C.},
	title = {Methods of investigating eye movements},
	volume = {32},
	number = {9},
	pages = {581--591},
	year = {1948},
	%doi = {10.1136/bjo.32.9.581},
	publisher = {BMJ Publishing Group Ltd},
	%issn = {0007-1161},
	%URL = {https://bjo.bmj.com/content/32/9/581},
	%eprint = {https://bjo.bmj.com/content/32/9/581.full.pdf},
	journal = {British Journal of Ophthalmology}
}

@inproceedings{salvucci2000,
  author = {Salvucci, Dario and Goldberg, Joseph},
  year = {2000},
  month = {01},
  pages = {71-78},
  title = {Identifying fixations and saccades in eye-tracking protocols},
  journal = {Proceedings of the Eye Tracking Research and Applications Symposium},
  %doi = {10.1145/355017.355028}
}

@article {zemblys2017,
	author = {Zemblys, Raimondas and Niehorster, Diederick C. and Komogortsev, Oleg and Holmqvist, Kenneth},
	title = {Using machine learning to detect events in eye-tracking data},
	volume = {50},
	year = {2017},
  month = {2},
	%doi = {10.3758/s13428-017-0860-3},
	publisher = {BMJ Publishing Group Ltd},
	%issn = {1554-3528},
	%URL = {https://doi.org/10.3758/s13428-017-0860-3},
	journal = {Behavior Research Methods}
}

@article{zemblys,
  author = {Zemblys, Raimondas and Niehorster, Diederick and Holmqvist, Kenneth},
  year = {2018},
  month = {10},
  pages = {},
  title = {gazeNet: End-to-end eye-movement event detection with deep neural networks},
  volume = {51},
  journal = {Behavior Research Methods},
  %doi = {10.3758/s13428-018-1133-5}
}

@article{fuhl2021,
  author    = {Wolfgang Fuhl},
  title     = {Fully Convolutional Neural Networks for Raw Eye Tracking Data Segmentation,
               Generation, and Reconstruction},
  journal   = {CoRR},
  volume    = {abs/2002.10905},
  year      = {2020},
  %url       = {https://arxiv.org/abs/2002.10905},
  %eprinttype = {arXiv},
  %eprint    = {2002.10905},
  %timestamp = {Tue, 03 Mar 2020 14:32:13 +0100},
  %biburl    = {https://dblp.org/rec/journals/corr/abs-2002-10905.bib},
  %bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{holmqvist2011,
  author = {Holmqvist, Kenneth and Nyström, Marcus and Andersson, Richard and Dewhurst, Richard and Jarodzka, Halszka and van de Weijer, Joost},
  year = {2011},
  month = {01},
  pages = {},
  title = {Eye Tracking: A Comprehensive Guide To Methods And Measures}
}

@article{hubel1974,
  title={Uniformity of monkey striate cortex: A parallel relationship between field size, scatter, and magnification factor},
  author={David H. Hubel and Torsten N. Wiesel},
  journal={Journal of Comparative Neurology},
  year={1974},
  volume={158}
}

@book{mitchell1997,
  title={Machine Learning},
  author={Mitchell, T.M.},
  isbn={9780071154673},
  lccn={97007692},
  series={McGraw-Hill International Editions},
  url={https://books.google.no/books?id=EoYBngEACAAJ},
  year={1997},
  publisher={McGraw-Hill}
}

@article{mcculloch1943,
  title={A logical calculus of the ideas immanent in nervous activity},
  author={McCulloch, Warren S. and Pitts, Walter},
  journal={The bulletin of mathematical biophysics},
  year={1943},
  volume={5}
}

@book{russell2009,
  title={Artificial Intelligence: a modern approach},
  author={Russell, Stuart J. and Norvig, Peter},
  edition={3},
  year={2009},
  publisher={Pearson}
}

@book{goodfellow2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    %note={\url{http://www.deeplearningbook.org}},
    year={2016}
}

@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}

@inproceedings{zemblys2016,
author = {Zemblys, Raimondas},
year = {2016},
month = {11},
pages = {},
title = {Eye-movement event detection meets machine learning}
}