\section{Classification} \label{sec:disc_Classification}

% Looking at section \_, it can further be observed that even with a limited supply of decently labeled data sets, we can train multiple models that surpass the classification accuracies of \_ algorithm in the binary classification problem. Even concerning multi-class classification, some of our models perform well given the underlying data. 

\subsection{Binary}
In section \ref{sec:pr_TraditionalClassificationMethods}, 
Section \ref{sec:pr_TraditionalClassificationMethods} served as an introduction to the myriad of manually coded algorithms available for eye event classification. The author focused on the IDF and IVT algorithms for this thesis, mainly for their simple implementations. Another factor, however, was that most newer and more advanced alternatives are heavily reliant on an estimate of eye movement velocity. Since this metric is limited for eye trackers with relatively low-frequency sampling rates, it would prove challenging to fully implement on our low-cost commercial hardware. 

The performance of these algorithms is visualized in figure \ref{fig:res_BinaryClassification}. However, for reasons elaborated in section \ref{sec:pr_TraditionalClassificationMethods}, they do not explicitly classify both fixations and saccades but instead assume the unclassified event to be the other. For this reason, a characteristic of most manually coded eye event classification algorithms is that they require data utterly void of anything but saccades and fixation to ensure proper function. However, for the binary classification problem and with this fact in mind, they perform very well, as is evident by their near-perfect correlation with the ground truth.

\subsection{Multi-class}

It is upon observing figure \ref{fig:res_MultiClassification} that the limitations of manually coded algorithms truly become apparent. Here the dataset to be classified includes fixations, saccades, and smooth pursuit. Indeed, as mentioned above, these algorithms immediately struggle to fully classify events that correspond with the ground truth when more than two classes are introduced. Since all events that are not fixations (for IDF) or saccades (for IVT) are assumed to be either saccades (for IDF) or fixations (for IVT), smooth pursuits are left unclassified. Our machine learning model, however, solves this problem impressively well. Since it makes classifications based upon several distinct features of the dataset, it is able to distinguish between all three classes.

What seems particularly interesting from the classification results of figure \ref{fig:res_MultiClassification} is that if one were to implement both the IDF and the IVT algorithm in sequence, the presence of smooth pursuits could be recognized as their collective unclassified samples. In fact, this is likely exactly what the machine learning model does under the hood. From figure \ref{fig:res_FeatureImportance}, it is evident that the dispersion and velocity features detailed in section \ref{sec:meth_FeatureGeneration} play a significant role when the distinction between classes is to be determined. Recalling from \ref{sec:pr_TraditionalClassificationMethods}, these are the same features on which the IDF and IVT algorithms determine classification, so the above result is not surprising. 

From the figures discussed, it seems clear that our machine learning model emerges as the most accurate and robust classification method when multiple classes need to be determined. However, since it requires a reasonably large and well-labeled dataset to train, it is not necessarily the best when only binary classification is needed. The manual operation of parameter tuning is usually considered one of the principal drawbacks of manually coded algorithms. Despite this, experience shows that the tuning of a machine learning model is undoubtedly a drawback of its own. Therefore, manually coded algorithms are likely still optimal for simple classification problems where only one feature is required for accurate classifications.

\subsection{Model Improvements}
While the model presented solves our initial eye event classification problem, it is not even close to the most optimal given the classification problem. Sadly, the author did not research the prospects enough to implement such a model. Some solutions come to mind, however. For instance, one particular shortcoming of using a classical machine learning model is the need for manually designed features. As described in section \ref{sec:meth_FeatureGeneration}, all features used for classification are selected by an educated assumption of its inherent correlation with eye movement. However, an educated assumption is still merely an assumption, so the model would likely significantly improve if it generated its features as a set of hidden layers in a neural network.

