\section{Tobii ET5 Evaluation} \label{sec:disc_TobiiET5Evaluation}

%Ts: 
%Pc: What can be observed by empirical data
% From the above results, there are mainly two things to note for rating the performance from our commercial eye tracker. First, it appears that the tracker is plenty capable of providing both accurate and abundant data for this particular use case. However, we might have seen even better results had the sampling rate been higher and illumination better. From table \_, we can observe a data range of \_ with as little as \_ noise. As is also made clear by figure \ref{fig:res_FirstHeatMapTest}, this suggests that the eye tracker is reliably able to distinguish between a wide range of individual gaze points. Finally, there is a clear correlation between sample labels and the feature set, demonstrated by figure \_. While this is also very dependent on the manual choice of features, it is still promising for the statistical inference that the data is coherent and representative of its labels.

From the data quality results of section \ref{sec:res_DataQuality}, we get a broad overview of the performance of Tobii ET5. The data quality is good, abundant, and relatively frequent. However, as is immediately apparent from both figures \ref{fig:res_GazePointTest} and \ref{fig:res_ScanpathTest}, there is a significant effect of bias, and some points on-screen are more disturbed than others. Corner points, particularly top corner points, seem to consistently output values that are slightly off their target values. This result is reasonable, considering how it calculates on-screen gaze points and where the tracker is mounted. By the horizontal fashion in which the IR- and camera sensors are placed in the tracker's casing, it is not unnatural that noise and measurement error is more pronounced for the detection of vertical eye movements. Additionally, since the tracker's mounting point is right below the center of the monitor, measurement error becomes more and more apparent the farther one is looking from this point
%The same effect of diminishing data quality at distant points from the sensor can also be seen on variance. 

In terms of data consistency, the results from \ref{fig:res_ScanpathTest} are very interesting. From this plot, we can see that although the scan paths tracked by Tobii ET5 are slightly off their target, they are remarkably consistent between consecutive tests. This consistency shows that the bias observed in both the gaze point and scan path tests might primarily be caused by poor tracker calibration or difficulties in designing a system that can discern gaze points universally between a wide variety of monitors and recording environments. Another interesting result from the scan path test is the peculiar dip in y-position when passing along the top border of the monitor. One explanation for this effect might be that the internal processing within the tracker recognizes that it consistently outputs values outside of the defined [0.0, 1.0] range and attempts to correct accordingly. Another and perhaps more likely explanation is that the sensor has trouble discerning purely lateral movements and slightly tilted lateral movements when the gaze is on the very ends of the screen, where it already struggles the most with calculation. Conversely, the scan path is very accurate on the opposite end of the screen, right above where the tracker is mounted.
% Impossible to keep environment completely agnostic for each test. Likely causes flaws in consistency.

The variance in data output is visualized in figure \ref{fig:res_DataDeviations} and given with hard numbers in table \ref{tab:res_DataStats}. However, since these results are based on just one empirical test, and we have established that the Tobii ET5 output rather unstable data, they should be taken with a grain of salt. From the violins of each plot, we can see deviations in coordinates from the mean value of one point on one axis. What is especially interesting here reflects what was discussed above: the fading data quality at the top and edge target points compared to the center point. The effect is also particularly noticeable on the y-axis, with generally higher deviations on the top row of violin plots, as well as the absolute value of the second std-entry in the coordinate tuples of \ref{tab:res_DataStats}. The same consequence is seen in the bias tuples, with higher values on the y-axis entry seven out of nine times. The bias entries also almost consistently tend upwards, indicated by negative values on the y-axis. This evidence and the fact that all variance entries lie within relatively low magnitudes argue for the point made above. Therefore, we can confidently conclude that the data output from Tobii ET5, although fairly biased towards higher vertical points, is very accurate.
%excluding possibly some edge points, lie confidently within the magnitude of about $5*10^(-3)$. 

Another thing to note is the shape of the violins of figure \ref{fig:res_DataDeviations}, with either long tails in one direction or something resembling two Gaussian distributions with a "dip" between them. If the data were only affected by bias and variance, one would expect to see only one Gaussian distribution centered on the mean value of all samples (or the target point if there were no biases). However, the results we see here are likely caused by data drift. The shape produced depends on whether the signal continuously drifts in one direction during recording or if it at some point "turns" and drifts in the opposite direction. If we take a closer look at the data gathered by the three-second fixation tests at the top-left target of figure \ref{fig:res_GazePointTest}, we can observe the very erratic gaze behavior of figure \ref{fig:res_DataDrift}. From these results, it is clear that drift is significant. It seems that there is little noise in the data at all and that the data deviations discussed above might be entirely caused by data drift. As detailed in section \ref{sec:hwds_TobiiEyeTracker5}, however, the "raw" data we get from Tobii ET5 is in reality lightly filtered for stability. 

% Given that we have no control over the internal processing done by Tobii, it becomes difficult to determine whether data drift is explainable and avoidable. Even so, some of it might be explained by ocular or physical noise that likely causes trouble for the Tobii internals. Physical noise refers to that of slight head or body movements, and a typical type of ocular noise are for instance microsaccades, detailed in section \ref{sec:bt_TheOculomotorSystem}. 
%Since this processing must be very sensitive, 

Finally, we see an actual use case for the eye tracker in figure \ref{fig:res_PaperHeatmap}. From this plot, none of the shortcomings discussed above are truly noticeable except perhaps some rightward bias in the lower regions of the screen, causing distortion. Nonetheless, one can clearly distinguish fixations on paragraphs from one another and even individual lines of text in some cases. The value of this data is self-evident. From this simple test, one can infer that the subject has paid particular attention to the abstract paragraph while seemingly glancing over other sections. They also seem to have completely ignored the header and foot-notes, and of the authors, they were the most focused on capturing the primary author.

%as the on-screen gaze-point is calculated from the angular position of the pupil, as well as point of origin and distance from screen.