\section{Classification} \label{sec:meth_Classification} 

Once eye movement data has been passed through the data acquisition pipeline, the classification dataset is imported to a Jupyter Notebook. The classification itself is done by three distinct models, implemented in object-oriented \texttt{Python}. 

One of the three models is a Random Forest Classifier, the background of which was explained in section \ref{sec:bt_ArtificialIntelligence}. This particular model was chosen for its proven dominance in eye movement event classification when compared to nine other machine-learning algorithms (\cite{zemblys2016}). It was implemented using the \texttt{Python} package \texttt{Scikit-Learn} (\cite{scikit-learn}), which allows for a streamlined training process without excessive overhead. Besides the default parameters, information gain was used to measure the quality of a split, and trees were given no maximum depth. Additionally, the weight of each class was set to be inversely proportional to class frequencies in the data. This was done to account for a surplus of smooth pursuit and fixation classes compared to saccades. Model training was done on a dataset generated by about five minutes of recorded eye movement data in the dynamic recording environment, with the author as the subject. 

The second and third models implemented one of each of the two algorithms defined in section \ref{sec:pr_TraditionalClassificationMethods}. Note that sample-to-sample velocities were already calculated during the feature extraction step. As such, algorithm \ref{alg:pr_IVT} (IVT) was simplified by the removal of lines 2-3. Also note that this is not the case for the IDT algorithm, as it requires the calculation of dispersion for a variable-sized sample window. Since the IVT algorithm only classifies saccades and the IDT algorithm only fixations, all other samples were set to be undefined.

When the first model was fully trained, two final datasets were made to compare the models. Since the IDT- and IVT algorithms are not designed to be used on datasets with smooth pursuit, one dataset was generated in the dynamic recording environment by excluding all stimulus movement except warping. The other dataset was generated with the same settings of the recording environment with which the training dataset was recorded. 